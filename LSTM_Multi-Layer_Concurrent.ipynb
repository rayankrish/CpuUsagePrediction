{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of LSTM\n",
    "## Variables to Consider\n",
    "<ul>\n",
    "    <li>Hidden Parameters (more seems better until 10)</li>\n",
    "    <li>Hidden Layers (more than 1 seems useless, makes sense because input is few dimensions)</li>\n",
    "    <li>Learning Rate (smaller learning rate requires more epoches to achieve similar results)</li>\n",
    "    <li>Mini-Batch Size (seems to have slight improvement)</li>\n",
    "    <li>Number Epochs</li>\n",
    "    <li>Sequence Length (4)</li>\n",
    "    <li>Length of Prediction (1)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13538,
     "status": "error",
     "timestamp": 1590900514206,
     "user": {
      "displayName": "Langston Nashold",
      "photoUrl": "",
      "userId": "03058483142038316977"
     },
     "user_tz": 300
    },
    "id": "VAzzi5jKnjvJ",
    "outputId": "42fe0153-d955-48ba-c761-2319f3dfad81"
   },
   "outputs": [],
   "source": [
    "#!pip uninstall statsmodels\n",
    "#!pip install pmdarima\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"using cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1590900464686,
     "user": {
      "displayName": "Langston Nashold",
      "photoUrl": "",
      "userId": "03058483142038316977"
     },
     "user_tz": 300
    },
    "id": "DzEKHrLmtEYI",
    "outputId": "b523f4cb-6c47-440e-89a7-0df85cf4fb02"
   },
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self, num_layers = 1, hidden_size = 10, batch_size = 100, seq_len = 50, pred_len = 50, num_epochs = 20, learning_rate = 0.01, dropout = 1):\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"{}-{}-{}-{}-{}-{}-{}-{}\".format(self.num_layers, self.hidden_size, self.batch_size, self.seq_len, self.pred_len, self.num_epochs, self.learning_rate, self.dropout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXV_VIWvO-he"
   },
   "source": [
    "Following Code Adapted from ([github sample](https://github.com/spdin/time-series-prediction-lstm-pytorch/blob/master/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21600, 1)\n"
     ]
    }
   ],
   "source": [
    "def readData(file='samples/WY.csv', freq=1):\n",
    "    data = pd.read_csv(file, delimiter=',', index_col=0, parse_dates=True)\n",
    "\n",
    "    #plt.figure(figsize=(20, 4))\n",
    "    #plt.plot(data)\n",
    "    #print(data)\n",
    "    data = data.resample(str(freq) + 'T').mean()\n",
    "    raw_values = np.asarray(data['CpuUtilizationAverage']).reshape(data.shape[0], 1)\n",
    "    #plt.plot(data)\n",
    "    #plt.show()\n",
    "    #print(raw_values)\n",
    "    return raw_values\n",
    "\n",
    "training_set = readData()\n",
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESj__1lcPQzg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17200, 50, 1])\n",
      "torch.Size([17200, 50])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# just used to store some data variables\n",
    "class Data:\n",
    "    pass\n",
    "\n",
    "def large_sliding_windows(data, seq_length, pred_length=2):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-pred_length+1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length:i+seq_length+pred_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "def get_concurrent():\n",
    "    data = np.zeros((50, 21600))\n",
    "    for i, state in enumerate(listdir(\"samples/\")):\n",
    "        training_set = readData(\"samples/\"+state)\n",
    "        training_set = training_set.flatten()\n",
    "        data[i] = training_set\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(21600-1):\n",
    "        _x = data[:,i:(i+1)]\n",
    "        _y = data[:,i+1]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def generateData(training_set, d, params):\n",
    "    d.sc = MinMaxScaler()\n",
    "    training_data = d.sc.fit_transform(training_set) # normalizes the data\n",
    "\n",
    "    seq_length = params.seq_len # parameter\n",
    "    pred_len = params.pred_len # parameter\n",
    "    x, y = get_concurrent()\n",
    "\n",
    "    batch_size= params.batch_size\n",
    "    d.max_size = int(batch_size*(len(y)//batch_size))\n",
    "    d.train_size = int(batch_size*(d.max_size*(0.8)//batch_size)) #train_size = int(len(y) * 0.67)\n",
    "    d.test_size = d.max_size-d.train_size\n",
    "    #test_size = len(y) - train_size\n",
    "\n",
    "    d.dataX = Variable(torch.Tensor(np.array(x[0:d.max_size])))\n",
    "    d.dataY = Variable(torch.Tensor(np.array(y[0:d.max_size])))\n",
    "\n",
    "    d.trainX = Variable(torch.Tensor(np.array(x[0:d.train_size])))\n",
    "    d.trainY = Variable(torch.Tensor(np.array(y[0:d.train_size])))\n",
    "    train_data = TensorDataset(d.trainX, d.trainY)\n",
    "    d.train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size) #primary\n",
    "\n",
    "    d.testX = Variable(torch.Tensor(np.array(x[d.train_size:d.max_size])))\n",
    "    d.testY = Variable(torch.Tensor(np.array(y[d.train_size:d.max_size])))\n",
    "    #test_data = TensorDataset(testX, testY)\n",
    "    test_data = TensorDataset(d.dataX, d.dataY)\n",
    "    d.test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size) #primary\n",
    "    return d\n",
    "data = Data()\n",
    "params = Parameters()\n",
    "generateData(training_set, data, params)\n",
    "print(data.trainX.shape)\n",
    "print(data.trainY.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4300, 50])\n"
     ]
    }
   ],
   "source": [
    "## Generate Naive Examples\n",
    "\n",
    "def generateNaive(d, params):\n",
    "    mean = d.trainY.mean()\n",
    "    mean_forecasts = np.full(d.testY.shape, mean.item())\n",
    "    naive_forecasts = np.full(d.testY.shape, d.trainX[-1][-1].item())  # always predicts last provided\n",
    "    four_naive_forecasts = np.ones(d.testY.shape)\n",
    "    for row in four_naive_forecasts:\n",
    "        for i in range(params.pred_len):\n",
    "            row[i] = d.testX[i][-1].item()\n",
    "    four_mean_forecasts = np.ones(d.testY.shape)\n",
    "    for row, test_row in zip(four_mean_forecasts, d.testX):\n",
    "        for i in range(params.pred_len):\n",
    "            row[i] = np.mean(test_row.numpy())\n",
    "\n",
    "    #naive_forecasts = naive_forecasts.reshape(-1, 1)\n",
    "    #mean_forecasts = mean_forecasts.reshape(-1, 1)\n",
    "\n",
    "    denormalize=False\n",
    "\n",
    "    if denormalize:\n",
    "        naive_forecasts = sc.inverse_transform(naive_forecasts)\n",
    "        mean_forecasts = sc.inverse_transform(mean_forecasts)\n",
    "        four_naive_forecasts = sc.inverse_transform(four_naive_forecasts)\n",
    "        four_mean_forecasts = sc.inverse_transform(four_mean_forecasts)\n",
    "\n",
    "\n",
    "    global_naive = naive_forecasts.reshape(naive_forecasts.shape[:-2] + (-1,))\n",
    "    global_mean = mean_forecasts.reshape(mean_forecasts.shape[:-2] + (-1,))\n",
    "    local_naive = four_naive_forecasts.reshape(four_naive_forecasts.shape[:-2] + (-1,))\n",
    "    local_mean = four_mean_forecasts.reshape(four_mean_forecasts.shape[:-2] + (-1,))\n",
    "    return (global_naive, global_mean, local_naive, local_mean)\n",
    "\n",
    "naives  = generateNaive(data, params)\n",
    "print(data.testY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3dTo7J9PWI5"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, output_size, input_size, hidden_dim, n_layers, drop_prob=0):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        #x = x.long()\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        #print(lstm_out.shape)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        #out = self.dropout(lstm_out)\n",
    "        #print(lstm_out.shape)\n",
    "        #out = self.fc(lstm_out) # linear transform from hidden dims to output_size\n",
    "        #print(out.shape)\n",
    "        #out = out.view(batch_size, -1) #-1 means size will be infered\n",
    "        #print(out.shape)\n",
    "        #out = out[:,-2]\n",
    "        #print(out.shape)\n",
    "        #print(hidden[0][-1].shape)\n",
    "        h_out = hidden[0][-1].view(-1, self.hidden_dim)\n",
    "        out = self.fc(h_out)\n",
    "        #print(out.shape)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9AO0JvNKPZcE"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ARlW89KPanR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayan/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:47: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 613.20709\n",
      "Epoch: 10, loss: 351.50610\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, lstm, h, criterion):\n",
    "        self.lstm, self.h, self.criterion = lstm, h, criterion\n",
    "\n",
    "def train(d, params):\n",
    "    num_epochs = params.num_epochs#30 # seems to stabilize here, higher and it seems to overfit\n",
    "    learning_rate = params.learning_rate#0.01\n",
    "\n",
    "    input_size = 1 # required for this time series (value)\n",
    "    hidden_size = params.hidden_size#2 # hyper parameter\n",
    "    num_layers = params.num_layers#1 # hyper parameter\n",
    "\n",
    "    lstm = LSTM(params.pred_len, input_size, hidden_size, num_layers, params.dropout)\n",
    "    lstm.to(device)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "    #criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "    #optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "    h = lstm.init_hidden(params.batch_size)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        for x, y in d.train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            h = tuple([e.data for e in h])\n",
    "            outputs, h = lstm(x, h)\n",
    "            optimizer.zero_grad() # remove stored gradient\n",
    "\n",
    "            # obtain the loss function\n",
    "            #print(outputs.shape)\n",
    "            #print(outputs.shape)\n",
    "            #print(y.shape)\n",
    "            loss = criterion(outputs, y) #.squeeze()\n",
    "            #print(outputs)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "            #pass\n",
    "            \n",
    "    model = Model(lstm, h, criterion)\n",
    "    return model\n",
    "            \n",
    "model = train(data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUVXq6eYPbnx"
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nc8WL0XuPcxa"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d6360985c4fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataY_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d6360985c4fa>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, d, params, show_plot)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m#test_predict[i*100+j] = output[j].item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mtest_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test(model, d, params, show_plot=False):\n",
    "    model.lstm.eval()\n",
    "    test_predict = np.zeros((data.max_size, params.pred_len))\n",
    "    test_losses = []\n",
    "\n",
    "    for i, (x, y) in enumerate(d.test_loader):\n",
    "        model.h = tuple([each.data for each in model.h])\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output, model.h = model.lstm(x, model.h)\n",
    "        test_loss = model.criterion(output.squeeze(), y)\n",
    "        test_losses.append(test_loss.item())\n",
    "        for j in range(params.batch_size):\n",
    "            #test_predict.append(output[j].item())\n",
    "            #test_predict[i*100+j] = output[j].item()\n",
    "            for k in range(params.pred_len):\n",
    "                test_predict[j+i*100][k] = output[j][k].item()\n",
    "\n",
    "\n",
    "    #print(test_predict)\n",
    "\n",
    "    #data_predict = test_predict.reshape(-1, 1)#test_predict.data.numpy()\n",
    "    data_predict = test_predict\n",
    "    dataY_plot = d.dataY.data.numpy()\n",
    "    \n",
    "    data_predict_transform = d.sc.inverse_transform(data_predict)\n",
    "    dataY_plot_transform = d.sc.inverse_transform(dataY_plot)\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.figure(figsize=(20, 4))\n",
    "        plt.axvline(x=d.train_size, c='r', linestyle='--') # data shift from train to test\n",
    "        plt.plot(dataY_plot_transform)\n",
    "        plt.plot(data_predict_transform)\n",
    "        plt.suptitle('Time-Series Prediction')\n",
    "        plt.show()\n",
    "\n",
    "    #print(data_predict_transform)\n",
    "    #print(dataY_plot_transform)\n",
    "    return (data_predict[d.train_size:], dataY_plot[d.train_size:])\n",
    "\n",
    "preds, labels = test(model, data, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GYO9JliaG2g"
   },
   "source": [
    "Image is deceptive. Try ~100 samples to see a closer fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAA4fI6vaLvg"
   },
   "source": [
    "Accuracy Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rISXuL-3I1Bl"
   },
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "# Mean Average Percent Error\n",
    "def mape(preds, labels, prnt=False):\n",
    "    preds = preds.flatten()\n",
    "    labels = labels.flatten()\n",
    "    err = 0\n",
    "    for i, (pred, label) in enumerate(zip(preds, labels)):\n",
    "        denum = np.absolute(label) if np.round(label) !=0 else 50#np.max(labels) # this might be wrong\n",
    "        err += (np.absolute(pred-label) / denum)\n",
    "            \n",
    "    err /= preds.shape[0]\n",
    "    if prnt: print(\"MAPE - {}\".format(err))\n",
    "    return err\n",
    "    \n",
    "# Brier Score or Mean Squared Error\n",
    "def mse(preds, labels, prnt=False):\n",
    "    preds = preds.flatten()\n",
    "    labels = labels.flatten()\n",
    "    err = np.sum(np.power(preds-labels, 2)) / preds.shape[0]\n",
    "    if prnt: print(\"MSE - {}\".format(err))\n",
    "    return err\n",
    "    \n",
    "def mae(preds, labels, prnt=False):\n",
    "    preds = preds.flatten()\n",
    "    labels = labels.flatten()\n",
    "    err = (np.sum(np.absolute(preds-labels))) / preds.shape[0]\n",
    "    if prnt: print(\"MAE - {}\".format(err))\n",
    "    return err\n",
    "    \n",
    "# Root Mean Squared Error\n",
    "def rmse(preds, labels, prnt=False):\n",
    "    err = np.power(mse(preds, labels), 0.5)\n",
    "    if prnt: print(\"RMSE - {}\".format(err))\n",
    "    return err\n",
    "\n",
    "# Symmetric Mean Absolute Percentage Error\n",
    "# some issues in bias, but commonly used\n",
    "def smape(preds, labels, prnt=False):\n",
    "    preds = preds.flatten()\n",
    "    labels = labels.flatten()\n",
    "    err = 0\n",
    "    for (pred, label) in zip(preds, labels):\n",
    "        denum = np.absolute(pred)+np.absolute(label) if np.absolute(pred)+np.absolute(label) !=0 else np.max(labels) #check!!\n",
    "        err += (np.absolute(pred-label) / denum)\n",
    "    err /= preds.shape[0] # in textbook, also multiply by 200 but this might be for percentage?\n",
    "    if prnt: print(\"SMAPE - {}\".format(err))\n",
    "    return err\n",
    "\n",
    "#errors = [mape, mse, rmse, smape]\n",
    "errors = [mae, rmse, mape]\n",
    "\n",
    "def print_errors(preds, labels, prnt=False):\n",
    "    err_results = []\n",
    "    for error in errors:\n",
    "        err_results.append(error(preds, labels, prnt))\n",
    "    return err_results\n",
    "        \n",
    "print_errors(preds, labels)\n",
    "\n",
    "for naive in naives:\n",
    "\n",
    "    print_errors(naive, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "params.num_epochs=30\n",
    "params.num_layers=2\n",
    "params.dropout=0.5\n",
    "Parameters(1, 10, 100, 50, 50, 30, 0.01, 0)\n",
    "\n",
    "columns = ['MAE', 'RMSE', 'MAPE', 'MEAN_MAE', 'MEAN_RMSE', 'MEAN_MAPE', 'NAIVE_MAE', 'NAIVE_RMSE', 'NAIVE_MAPE']\n",
    "df = pd.DataFrame(columns = columns, dtype=np.float64)\n",
    "    \n",
    "for i, state in enumerate(listdir(\"samples/\")):\n",
    "    training_set = readData(\"samples/\"+state, freq=1)\n",
    "    data = Data()\n",
    "    generateData(training_set, data, params)\n",
    "    naives  = generateNaive(data, params)\n",
    "    model = train(data, params)\n",
    "    preds, labels = test(model, data, params)\n",
    "    #print(\"----- {} Results -----\".format(state.replace(\".csv\", \"\")))\n",
    "    err_results = print_errors(preds, labels)\n",
    "    #print(a_row.values)\n",
    "\n",
    "    for naive in naives:\n",
    "        err_results.extend(print_errors(naive, labels))   \n",
    "        \n",
    "    row_df = pd.DataFrame([err_results], index = [state.replace(\".csv\", \"\")])\n",
    "    df = pd.concat([row_df, df])\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "print(df.shape)\n",
    "df.to_csv(\"lstm-out/concur-{}.csv\".format(params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CPU_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
