{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pm\n",
    "from pmdarima import model_selection\n",
    "import statsmodels\n",
    "from pmdarima.pipeline import Pipeline\n",
    "from pmdarima import preprocessing\n",
    "from pmdarima import arima\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Percentage Error\n",
    "def mape(preds, labels):\n",
    "    err = 0\n",
    "    for (pred, label) in zip(preds, labels):\n",
    "        denum = np.absolute(label) if label !=0 else 100 # this might be wrong\n",
    "        err += (np.absolute(pred-label) / denum)\n",
    "    err /= preds.shape[0]\n",
    "    print(\"MAPE - {}\".format(err))\n",
    "    return err\n",
    "    \n",
    "# Brier Score or Mean Squared Error\n",
    "def mse(preds, labels):\n",
    "    err = np.sum(np.power(preds-labels, 2)) / preds.shape[0]\n",
    "    print(\"MSE - {}\".format(err))\n",
    "    return err\n",
    "\n",
    "# Mean Absolute Error\n",
    "def mae(preds, labels):\n",
    "    err = np.sum(np.abs(preds-labels)) / preds.shape[0]\n",
    "    print(\"MAE - {}\".format(err))\n",
    "    return err\n",
    "    \n",
    "# Root Mean Squared Error\n",
    "def rmse(preds, labels):\n",
    "    err = np.power(mse(preds, labels), 0.5)\n",
    "    print(\"RMSE - {}\".format(err))\n",
    "    return err\n",
    "\n",
    "# Calculates the error for MAE, RMSE, and RMSE\n",
    "# Returns the results in a list\n",
    "def calculate_errors(preds, labels):\n",
    "    return [fn(preds, labels) for fn in [mae, rmse, mape]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains an ARIMA model for every dataset, then makes a prediction on the test set. Models are saved to disk as a pickle file for reuse. Returns a dictionary of predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_path = 'arima_output'\n",
    "# Freq is the frequency in minutes to downsample to,\n",
    "# split is train/test set split. Parameters are (p,d,q)\n",
    "# Seasonal parameters are (P, D, Q). Assumes daily seasons\n",
    "# Each prediction set is in an (ARIMA, mean, naive) tuple\n",
    "def train_arima_models(freq=20, split=0.8, parameters=(1,0,1), seasonal_parameters = (3, 0, 3), load_from_disk=True):    \n",
    "    p, d, q= parameters\n",
    "    P, D, Q = seasona_parameters\n",
    "    seasonality = (24 * 60) // freq\n",
    "    \n",
    "    filenames = glob.glob('samples/*.csv')\n",
    "    datasets = [filename.split('/')[1].split('.')[0] for filename in filenames]\n",
    "\n",
    "    arima_maes = []\n",
    "    mean_maes = []\n",
    "    for dataset in datasets:\n",
    "        # Generates train and test sets \n",
    "        data = pd.read_csv('samples/' + dataset + '.csv', delimiter=',', index_col=0, parse_dates=True)\n",
    "        downsampled = data.resample(str(freq) + 'T').mean()\n",
    "        raw_values = np.asarray(downsampled['CpuUtilizationAverage'])\n",
    "        tsize = math.floor(raw_values.shape[0] * split)\n",
    "        train, test = model_selection.train_test_split(raw_values, train_size=tsize)\n",
    "\n",
    "        \n",
    "        model_filename = f\"{save_path}/models/{dataset}.arima\"\n",
    "        \n",
    "        # Train ARIMA models\n",
    "        if (not load_from_disk):\n",
    "            start = datetime.now()\n",
    "            model = arima.ARIMA((p,d,q), (P,D,Q,seasonality), method='powell')\n",
    "            model.fit(train)\n",
    "            end = datetime.now()\n",
    "            print(f\"Trained {dataset} in \" + str(end - start))\n",
    "            \n",
    "            # Save models to disk\n",
    "            pickle.dump(model, open(model_filename, \"wb\" ))\n",
    "        else: \n",
    "            model = pickle.load(open(model_filename, \"rb\" ))\n",
    "            \n",
    "            print(f\"Loaded {f} from disk\")\n",
    "\n",
    "        # Predict future\n",
    "        arima_forecast = model.predict(test.shape[0])\n",
    "        \n",
    "        #Calculate Naive predictions\n",
    "        mean = train.mean()\n",
    "        mean_forecast = np.ones(test.shape[0]) * mean\n",
    "        naive_forecast = np.ones(test.shape[0]) * train[-1]\n",
    "\n",
    "        # Create plot of prediction vs actual\n",
    "        fig, ax = plt.subplots()\n",
    "        x = np.arange(raw_values.shape[0])\n",
    "        plt.plot(x[:tsize], train, c='blue')\n",
    "        plt.plot(x[tsize:], model_forecasts, c='green')\n",
    "        plt.plot(x[tsize:], raw_values[tsize:], c='blue', alpha=0.3)\n",
    "        plt.xlabel('Time (Days)')\n",
    "        plt.ylabel('CPU Usage')\n",
    "        ticks = np.arange(0, raw_values.shape[0], seasonality)\n",
    "        tick_labels = [str(label) for label in ticks // seasonality]\n",
    "        ax = plt.gca()\n",
    "        plt.xticks(ticks)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        plt.draw()\n",
    "        plotname = f\"./save_path/plots/{dataset}.png\"\n",
    "        plt.savefig(plotname, format='png')\n",
    "\n",
    "        # Calculate errors\n",
    "        errors = []\n",
    "\n",
    "        for forecast in [model_forecasts, mean_forecasts, naive_forecasts]:\n",
    "            errors.extend(calculate_errors(forecast, test))\n",
    "            errors.extend(calculate_errors(forecast[:3], test[:3]))\n",
    "        \n",
    "        arima_maes.append(mae(model_forecasts, test))\n",
    "        mean_maes.append(mae(mean_forecasts, test))\n",
    "        \n",
    "        \n",
    "        row = pd.DataFrame([errors], index=[dataset], columns = columns, dtype=np.float64 )\n",
    "        df = pd.concat([row, df])\n",
    "\n",
    "    # Calculate avg stats\n",
    "    avg_row = df.mean(axis=0).rename('Average', inplace=True)\n",
    "    min_row = df.max(axis=0).rename('Maximum', inplace=True)\n",
    "    max_row = df.min(axis=0).rename('Minimum', inplace = True)\n",
    "    df = df.append(avg_row).append(min_row).append(max_row)\n",
    "\n",
    "    # Saves everything to CSV\n",
    "    df.to_csv(f\"{save_path}/all_results.csv\")\n",
    "    \n",
    "    # Separate CSV just for short term results\n",
    "    columns = ['3pt MAE','3pt MAPE', '3pt MEAN MAE','3pt MEAN MAPE']\n",
    "    short_term_df = df[columns]\n",
    "    short_term_df.to_csv(f\"{save_path}/short_term_results.csv\", float_format=\"%.2f\")\n",
    "\n",
    "    # Separate CSV just for long term results\n",
    "    columns = ['MAE', 'MAPE', 'MEAN_MAE', 'MEAN_MAPE']\n",
    "    long_term_df = df[columns]\n",
    "    long_term_df.to_csv(f\"{save_path}/long_term_results.csv\", float_format=\"%.2f\")\n",
    "    \n",
    "    # Creates graph showing MAE of all files \n",
    "    figure(num=None, figsize=(16, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    X = np.arange(50)\n",
    "    handle1 = plt.bar(X, arima_maes, color='blue', width = 0.25, tick_label=trim_filenames, label = 'ARIMA')\n",
    "    handle2 = plt.bar(X+0.25, mean_maes, color='red', width = 0.25, tick_label=trim_filenames, label = 'Naive Mean')\n",
    "    plt.legend(handles = [handle1, handle2])\n",
    "    plt.ylabel(\"Mean Absolute Error\")\n",
    "    plt.xlabel(\"Time Series\")\n",
    "    filename = f\"{save_path}/mae_plot.png\"\n",
    "    plt.savefig(filename, dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    # Prints percent of times ARIMA outperformed Naive mean\n",
    "    tot = 0\n",
    "    for arima_mae, mean_mae in zip(arima_maes, mean_maes):\n",
    "        if (arima_mae < mean):\n",
    "            tot += 1\n",
    "    print(\"Percentage of times ARIMA outperformed mean:\")\n",
    "    print(tot / len(datasets) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
